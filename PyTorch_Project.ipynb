{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seyyedAlirezaGhazanfari/MovieRecommenderSystem/blob/main/PyTorch_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2qUM9rYj2L5"
      },
      "source": [
        "<div style=\"direction:rtl;line-height:300%;\">\n",
        "<font face=\"XB Zar\" size=5>\n",
        "<div align=center>\n",
        "    <font size=6>\n",
        "    باسمه تعالی\n",
        "    </font>\n",
        "    <br><br>\n",
        "    <font>\n",
        "    درس جبر خطی\n",
        "    <br>\n",
        "        <font size=3>\n",
        "            مدرس: حمیدرضا ربیعی، مریم رمضانی\n",
        "        </font>\n",
        "    </font>\n",
        "    <br><br>\n",
        "    <font>\n",
        "        <b> PyTorch پروژه</b>\n",
        "    </font>\n",
        "    <br>\n",
        "    <font size=3>\n",
        "     موعد تحویل: ۱۵ بهمن ۱۴۰۰ ساعت ۲۳:۵۹\n",
        "    </font>\n",
        "    <br>\n",
        "    <font size=4>\n",
        "    دستیاران آموزشی:\n",
        "        پویا اسمعیلی،\n",
        "        علی بالاپور\n",
        "    </font>\n",
        "    <br>\n",
        "        <font size=2>\n",
        "        دانشگاه صنعتی شریف\n",
        "        <br>\n",
        "        دانشکده مهندسی کامپیوتر\n",
        "    </font>\n",
        "</div>\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie0Z27UOj2MH"
      },
      "source": [
        "<div align= \"justify\" dir=\"rtl\">\n",
        "<font face=\"Calibri\" size=4>\n",
        "    <h1>مقدمه</h1>\n",
        "    هدف این پروژه تعمیق مفاهیم تدریس شده در کلاس درس  و آشنایی دانشجویان با کاربردهای جبرخطی است. برای انجام این پروژه، نکات زیر را در نظر داشته باشید:\n",
        "    <ul>\n",
        "        <li>یکی از اهداف این پروژه آشنایی بیشتر دانشجویان با توابع و مفاهیم PyTorch است. بنابراین پیاده‌سازی خواسته‌های هر سوال حتما باید با استفاده از PyTorch باشد.</li>\n",
        "        <li>انجام این پروژه به صورت انفرادی است.</li>\n",
        "        <li>در مجموع این پروژه 100 نمره بوده که سوال اول 40 نمره و سوال دوم 60 نمره دارد. توجه داشته باشید پیاده‌سازی این پروژه اختیاری بوده و نمره اختصاص شده برابر 0.8 از نمره کل است.</li>\n",
        "        <li>توجه داشته باشید که نمی‌توانید از تاخیر مجاز برای این پروژه استفاده نمایید. (به علت اختیاری بودن پروژه و همچنین نزدیک بودن ددلاین به مهلت ارسال نمرات به آموزش)</li>\n",
        "        <li>پس از ددلاین مشخص شده برای پروژه، یک جلسه کوتاه برای تحویل حضوری پروژه برگزار می‌گردد.</li>\n",
        "        <li>برای راحتی کار، توصیه می‌شود که از google colab استفاده نمایید.</li>\n",
        "        <li>\n",
        "        برای این پروژه لازم است که علاوه بر پیاده‌سازی خواسته سوال، توضیح کوتاهی در مورد نحوه عملکرد کد پیاده‌سازی‌شده نوشته شود.\n",
        "        </li>\n",
        "    </ul>\n",
        "    </font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV_5Tc2fj2MJ"
      },
      "source": [
        "<div align= \"justify\" dir=\"rtl\">\n",
        "<font face=\"Calibri\" size=3>\n",
        "    <h1>الگوریتم PCA </h1>\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT1F0AZSj2MK"
      },
      "source": [
        "<div align= \"justify\" dir=\"rtl\">\n",
        "<font face=\"Calibri\" size=4>\n",
        "    در این تمرین قصد داریم که با استفاده از فریمورک PyTorch و ابزارهای آن، الگوریتم \n",
        "    <a href='https://en.wikipedia.org/wiki/Principal_component_analysis'>PCA (Principal Component Analysis)</a> را روی دیتاست Iris پیاده‌سازی کنیم.  <br>\n",
        "دیتاستی که در این قسمت در نظر گرفته‌شده، دیتاست iris است. این دیتاست شامل داده‌های سه نوع گل زنبق بوده که بر اساس 4 ویژگی، دسته‌بندی شده‌اند (در جلسات اولیه درس در مورد این دیتاست صحبت کردیم). یکی از اقدامات ابتدایی در یک پروژه مربوط به یادگیری ماشین و علوم داده، \n",
        "    <a href=''https://en.wikipedia.org/wiki/Exploratory_data_analysis>EDA(Exploratory Data Analysis)</a>\n",
        "    است. در EDA قصد داریم تا با رسم نمودارهای مختلف و استفاده از ابزارهای موجود، یک دید کلی نسبت به داده بدست بیاوریم. اما برای رسم ساده‌ترین نمودارها (مانند نمودار scatter) برای داده‌هایی که دارای بیش از دو یا سه ویژگی دارند، ممکن است دشوار باشد. برای همین از الگوریتم‌های کاهش ابعاد استفاده می‌گردد. مشهورترین الگوریتم‌ها برای این کار، PCA و t-SNE می‌باشند. <br>\n",
        "در این تمرین شما باید دیتاست \n",
        "    <a href='https://archive.ics.uci.edu/ml/datasets/iris'>Iris</a>\n",
        "    (که در فایل iris.csv قرار دارد) را به یک تنسور دو بعدی تبدیل نمایید و الگوریتم PCA را با استفاده از توابع محاسباتی و مربوط به جبرخطی پایتورچ، بر روی این تنسور پیاده‌سازی کنید. سپس نتایج به‌دست آمده را با استفاده از کتابخانه‌های مصورسازی پایتون (مانند pyplot) بر روی یک scatter plot (با اعمال برچسب هر داده) رسم کنید. <br>\n",
        "توجه داشته باشید که استفاده از هرگونه کتابخانه برای پیاده‌سازی مستقیم الگوریتم PCA مجاز نیست. \n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf0K30Slj2MM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984656a4-10f7-4467-8b1b-d791ed63dc56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "# Your Code\n",
        "#imports\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "import torch.utils.data as data_utils\n",
        "import pandas as pd\n",
        "#end of imports\n",
        "#download dataset\n",
        "url = \"https://github.com/seyyedAlirezaGhazanfari/recommendation_system/blob/main/Iris.csv?raw=true\"\n",
        "#end of download dataset\n",
        "device = torch.device(\"cuda:0\")\n",
        "iris_data = pd.read_csv(url)\n",
        "#standardization and create tensor from dataframe\n",
        "target = None\n",
        "for col in [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]:\n",
        "  temp_data = iris_data[col].values\n",
        "  temp_tensor = torch.tensor(temp_data, device = device)\n",
        "  mean = temp_tensor.mean()\n",
        "  std = temp_tensor.std()\n",
        "  standardized = torch.tensor(data = (temp_tensor - mean)/std)\n",
        "  stnd_tensor = torch.stack((standardized, ), dim = -1)\n",
        "  if col == \"SepalLengthCm\":\n",
        "    target = stnd_tensor\n",
        "  else:\n",
        "    target = torch.cat((target, stnd_tensor), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfzqPubNM1Nl"
      },
      "outputs": [],
      "source": [
        "#covariance matrix\n",
        "t_tgt = target.T\n",
        "cov_mx = torch.cov(input = t_tgt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdRFkpe4P_xy"
      },
      "outputs": [],
      "source": [
        "#compute eigen values and eigen vectors of covariance matrix\n",
        "eigen_vals, eigen_vecs = torch.linalg.eig(input = cov_mx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slraE2LYbwcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b37e554-5edb-4819-d213-b54a589fa4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ../aten/src/ATen/native/Copy.cpp:244.)\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#ordering eigenvalues and eigenvectors\n",
        "eigen_vals = eigen_vals.float()\n",
        "eigen_vecs = eigen_vecs.float()\n",
        "idex = eigen_vals.argsort(descending=True)\n",
        "eigen_vals = eigen_vals[idex]\n",
        "eigen_vecs = eigen_vecs[:,idex]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsUPrs77eOoT"
      },
      "outputs": [],
      "source": [
        "#create featured vector\n",
        "fvec = eigen_vecs[:, 0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIuIDYOifzOa"
      },
      "outputs": [],
      "source": [
        "#create new dataset\n",
        "nds = torch.matmul(fvec.T, t_tgt.float())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgEdKR0xtkyB"
      },
      "outputs": [],
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(iris_data['Species'].to_list())\n",
        "list(le.classes_)\n",
        "labels = list(le.transform(iris_data['Species'].to_list()))\n",
        "data = {\"PCA1\": nds[0, :].cpu(), \"PCA2\": nds[1, :].cpu(), \"Species\": iris_data['Species'].to_list()}\n",
        "ndf = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "Xk43NG9Oh4DJ",
        "outputId": "53042510-58dd-403a-e0d9-c67b9c745621"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0c53e4e3ba94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PCA1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PCA2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcolor_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Iris-setosa\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Iris-versicolor\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"green\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Iris-virginica\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"red\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PCA1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PCA2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mcolor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mndf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Species'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "plt.xlabel(\"PCA1\")\n",
        "plt.ylabel(\"PCA2\")\n",
        "color_dict = {\"Iris-setosa\": \"blue\", \"Iris-versicolor\": \"green\", \"Iris-virginica\": \"red\"}\n",
        "plt.scatter(ndf['PCA1'], ndf['PCA2'], c = [ color_dict[i] for i in ndf['Species'] ])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align= \"justify\" dir=\"rtl\">\n",
        "<font face=\"Calibri\" size=4>\n",
        "تحلیل:\n",
        "<br>\n",
        "الگوریتم PCA که کدش را بالاتر زده ام از چند مرحله اساسی تشکیل شده که مختصر آنها را توضیح می‌دهم.\n",
        "<br>\n",
        "ابتدا تنسوری که از دیتاست بدست آمده است یک تنسور استاندارد شده استخراج میکنیم.\n",
        "سپس کوواریانس تنسور استاندارد شده را محاسبه میکنیم. تنسور کوواریانس را از طریق eigen decomposition تجزیه میکنیم و مقادیر و بردار های ویژه را بدست می آوریم. حال عملیات مرتب سازی مقادیر ویژه و بردار های ویژه را انجام میدهیم و پس از آن بردار های ویژه ای که متناظر با فیچر های مورد نظر ما هستند را فقط در نظر میگیریم. در این جا من دو بردار ویژه ای که بیشترین اطلاعات را به ما می دادند را انتخاب کردم.\n",
        "<br>\n",
        "حاصل را ضرب در تنسور استاندارد شده اولیه میکنیم و بدین ترتیب دیتا های متناظر دو فیچری که مد نظر بودند را بدست آورده ایم کافیست حال لیبل ها را نیز به آنها اضافه کنیم تا بتوانیم آنها را تحلیل کنیم.\n",
        "</font>\n",
        "</div>"
      ],
      "metadata": {
        "id": "XQR8E1G2Ns_b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quSZ9Ea-j2MP"
      },
      "source": [
        "<div align= \"justify\" dir=\"rtl\">\n",
        "<font face=\"Calibri\" size=3>\n",
        "    <h1>سیستم توصیه‌گر (Recommender System)</h1>\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SltwmPLRj2MP"
      },
      "source": [
        "<div align= \"justify\" dir=\"rtl\">\n",
        "<font face=\"Calibri\" size=4>\n",
        "در این تمرین قصد داریم که با استفاده از فریمورک PyTorch و ابزارهای آن، یک سیستم توصیه‌گر (یا recommender system) ساده را پیاده‌سازی کنیم.\n",
        "<br> \n",
        "برای پیاده‌سازی این سیستم، شما یک جدول از امتیاز کاربران (از ۱ تا ۵) به فیلم‌ها دارید (در فایل ratings.csv). ستون‌های این جدول، شناسه‌ی کاربر، شناسه‌ی فیلم و امتیاز هستند. برای استفاده از این داده‌ها باید آن‌ها را تبدیل به ماتریسی از امتیاز هر کاربر به هر فیلم کنید. البته باید توجه کنید بیشتر درایه‌های این ماتریس نامشخص (امتیاز صفر) بوده و لازم است به جای ‌ان‌ها یک عدد قرار دهید. در ادامه روش‌های مختلف پر کردن این درایه‌ها توضیح داده می‌شود.\n",
        "<br>\n",
        "برای بررسی عملکرد سیستم، \n",
        "<!-- لازم است ابتدا تعدادی از داده‌های اولیه جدا شوند. بنابراین ۱۰ درصد از سطرهای جدول اولیه را به طور رندوم جدا کرده و از جدول حذف کنید. حال -->\n",
        " سیستم توصیه‌گر شما با یادگیری داده‌ها، امتیازی از طرف هر کاربر به هر فیلم نسبت می‌دهد. اگر این امتیازها را $y$ نامیده و امتیاز‌های حذف شده از جدول اولیه $\\hat{y}$ باشند، خطای سیستم به صورت\n",
        "$$E = \\Sigma_i (y - \\hat{y})^2$$\n",
        "تعریف می‌شود. برای هر یک از راه‌حل‌های خود، این خطا را برای خانه‌هایی که در دیتاست اولیه مقادیر بین ۱ تا ۵ دارند، حساب کنید.\n",
        "<br>\n",
        "در طراحی سیستم می‌توانید از تجزیه‌ی SVD استفاده کنید. برای این کار باید ابتدا درایه‌های نامشخص را پر کنید. برای این کار، روش‌های زیر را امتحان کرده و خطای سیستم در هر حالت را مقایسه کنید. سپس، از بهترین روش در سیستم نهایی خود استفاده کنید.\n",
        "<ol>\n",
        "<li>قرار دادن صفر به جای همه‌ی مقادیر نامشخص</li>\n",
        "<li>قرار دادن میانگین امتیاز هر فیلم در درایه‌های نامشخص آن فیلم</li>\n",
        "<li>استفاده از میانه‌ی امتیازهای هر فیلم در درایه‌های نامشخص آن فیلم</li>\n",
        "</ol>\n",
        "<br> \n",
        "برای این تمرین لازم است که شما با استفاده از مفاهیم تدریس شده در کلاس درس و ابزارهای پایتورچ، این سیستم توصیه گر ساده را پیاده‌سازی کنید و خطای آن را محاسبه کنید. استفاده از ابزارهای pandas و matplotlib در کنار pytorch مجاز بوده و هر گونه استفاده از numpy غیر مجاز است.\n",
        "\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/seyyedAlirezaGhazanfari/recommendation_system/blob/main/ratings.csv?raw=true\"\n",
        "device = torch.device(\"cuda:0\")\n",
        "data = pd.read_csv(url)\n",
        "users = data['userId'].unique() #list of all users\n",
        "movies = data['movieId'].unique() #list of all movies\n",
        "movie_id_max = movies.max()\n",
        "user_id_max = users.max()\n",
        "def decomposition(matrix, k):\n",
        "  U, s, Vh = torch.linalg.svd(matrix)\n",
        "  s = torch.diag(s)\n",
        "  U = U[:, 0:k]\n",
        "  Vh = Vh[0:k, :]\n",
        "  s = s[0:k, 0:k]\n",
        "  Us = torch.mm(U, s)\n",
        "  UsV = torch.mm(Us, Vh)\n",
        "  return UsV\n",
        "def sse(matrix, prediction, movies, users):\n",
        "  error = 0\n",
        "  for movie_id, user_id in zip(movies, users):\n",
        "    error = error + (matrix[user_id - 1, movie_id - 1] - prediction[user_id - 1, movie_id - 1])**2\n",
        "  return error\n",
        "number_of_features = 200"
      ],
      "metadata": {
        "id": "_tNonCXjPYQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_zero_matrix(users, movies, ratings, user_max_id, movie_max_id):\n",
        "  matrix = torch.zeros(size = (user_max_id, movie_max_id))\n",
        "  for user_id, movie_id, rating in zip(users, movies, ratings):\n",
        "    matrix[user_id - 1, movie_id - 1] = rating\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "142NysQW1QCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mean_matrix(matrix2, movies):\n",
        "  for movie in movies:\n",
        "    res = matrix2[:, movie - 1]\n",
        "    list_of_zeros = torch.isnan(matrix2[:, movie - 1])\n",
        "    arr = torch.masked_select(matrix2[:, movie - 1], ~list_of_zeros)\n",
        "    item_means = torch.mean(arr, axis=0)\n",
        "    res[res.isnan()] = item_means\n",
        "    matrix2[:, movie - 1] = res\n",
        "  return matrix2"
      ],
      "metadata": {
        "id": "P3B9izDi111s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_median_matrix(matrix3, movies):\n",
        "  for col in movies:\n",
        "    res = matrix3[:, col - 1]\n",
        "    list_of_zeros = torch.isnan(matrix3[:, col - 1])\n",
        "    arr = torch.masked_select(matrix3[:, col - 1], ~list_of_zeros)\n",
        "    item_means = torch.median(arr)\n",
        "    res[res.isnan()] = item_means\n",
        "    matrix3[:, col - 1] = res\n",
        "  return matrix3"
      ],
      "metadata": {
        "id": "tox3-5BH2Wq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies = data['movieId']\n",
        "users = data['userId']\n",
        "ratings = data['rating']\n",
        "user_max_id = users.max()\n",
        "movie_max_id = movies.max()\n",
        "matrix = create_zero_matrix(users, movies, ratings, user_max_id, movie_max_id)\n",
        "pred = decomposition(matrix, number_of_features)\n",
        "error1 = sse(matrix, pred, movies, users)\n",
        "print(error1)\n",
        "#end of zero way\n",
        "matrix2 = torch.clone(matrix)\n",
        "matrix2[matrix2 == 0] = torch.nan\n",
        "matrix3 = torch.clone(matrix2)\n",
        "#start of mean way\n",
        "matrix2 = create_mean_matrix(matrix2, movies)\n",
        "pred = decomposition(matrix2, number_of_features)\n",
        "error2 = sse(matrix2, pred, movies, users)\n",
        "print(error2)\n",
        "#end of mean way\n",
        "#start of median way\n",
        "matrix3 = create_median_matrix(matrix3, movies)\n",
        "pred = decomposition(matrix3, number_of_features)\n",
        "error3 = sse(matrix3, pred, movies, users)\n",
        "print(error3)\n",
        "#end of median way"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Qz1sWDihmp",
        "outputId": "ca7f1e40-5d9f-45bf-a85b-9e71a327935c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(103087.8125)\n",
            "tensor(12851.5381)\n",
            "tensor(14169.8037)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matrix2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZA5BX802iSy",
        "outputId": "499ebfac-f332-4d31-f1f6-b502d68f6e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5.0000, 3.0000, 4.0000,  ..., 2.0000, 3.0000, 3.0000],\n",
            "        [4.0000, 3.2061, 3.0333,  ..., 2.0000, 3.0000, 3.0000],\n",
            "        [3.8783, 3.2061, 3.0333,  ..., 2.0000, 3.0000, 3.0000],\n",
            "        ...,\n",
            "        [5.0000, 3.2061, 3.0333,  ..., 2.0000, 3.0000, 3.0000],\n",
            "        [3.8783, 3.2061, 3.0333,  ..., 2.0000, 3.0000, 3.0000],\n",
            "        [3.8783, 5.0000, 3.0333,  ..., 2.0000, 3.0000, 3.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommends(user_id, matrix, movie_id_max):\n",
        "  ratings = matrix[user_id - 1, :]\n",
        "  data = {'movie_id': list(range(1, movie_id_max + 1)), 'rating': ratings}\n",
        "  df = pd.DataFrame(data = data)\n",
        "  df.sort_values(by = 'rating', ascending = False, inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "Uuh5cwhT3fOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 1\n",
        "number_of_recommends = 10\n",
        "print(get_recommends(user_id, matrix2, movie_id_max).head(n = number_of_recommends))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJdYTyvx41Cl",
        "outputId": "4297b8af-4065-483f-cd2d-a6371c9f6d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      movie_id  rating\n",
            "0            1     5.0\n",
            "153        154     5.0\n",
            "126        127     5.0\n",
            "128        129     5.0\n",
            "136        137     5.0\n",
            "1466      1467     5.0\n",
            "149        150     5.0\n",
            "151        152     5.0\n",
            "164        165     5.0\n",
            "80          81     5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align= \"justify\" dir=\"rtl\">\n",
        "<font face=\"Calibri\" size=4>\n",
        "در این مسئله ابتدا دیتاست مد نظر را به تنسور تبدیل میکنیم. تنسوری که برای این دیتاست در نظر گرفته ام بدین گونه است که ابعاد آن مطابق بیشترین ایدی کاربر و بیشترین ایدی فیلم میباشد(باتوجه به این مورد که ایدی ها در این مسئله هر دو عدد هستند) پس بدین صورت یک ماتریس اسپارس داریم که بیشتر درایه های آن ۰ هستند پس در  حالت دیفالت ماتریسی که داریم حالت اول را برای پر کردن درایه های خالی استفاده کرده است پس ابتدا روش اول را انجام میدهیم و ارور را محاسبه میکنیم و سپس بجای درایه هایی که ۰ هستند nan قرار میدهیم و به دو روش بعدی میپردازیم.\n",
        "<br>\n",
        "برای بدست آوردن ماتریس predictions از روش svd استفاده میکنیم و تعداد فیچر دیفالتی که مد نظر قرار میدهیم نیز ۲۰۰ میباشد و این decomposition را انجام میدهیم و سپس با ضرب دوباره ماتریس های بدست آمده ماتریس predictions را تشکیل میدهیم و به محاسبه خطا میپردازیم.\n",
        "<br>\n",
        "همانطور که مشاهده میشود هر سه خطای بدست آمده را پرینت کردیم که بدین صورت است که با توجه به ۲۰۰ فیچر مهمی که در نظر گرفتیم خطای روش دوم که میانگین بود کمتر از همه است و مناسب استفاده سیستممان میباشد در جایگاه بعدی روش سوم است و ۰ قرار دادن در درایه های خالی بسیار خطای زیادی دارد.\n",
        "<br>\n",
        "خطوط آخر کد بالا نیز برای این مورد است که ایدی یک کاربر را به سیستم بدهیم و مثلا ۱۰ فیلم پیشنهادی برای این کاربر را نشان دهد.\n",
        "</div>\n",
        "</font>"
      ],
      "metadata": {
        "id": "LR31oUiqRUYX"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PyTorch Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}